{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broadband-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantities as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import argv\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "import numba\n",
    "from scipy.signal.windows import gaussian\n",
    "from tick.hawkes import SimuInhomogeneousPoisson\n",
    "from tick.base import TimeFunction\n",
    "from elephant.spike_train_generation import homogeneous_poisson_process\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "destroyed-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def outside_pattern(spiketrain,new_spiketrain,pattern_times):\n",
    "    actual_pattern = 0\n",
    "    actual_spike = 0\n",
    "    for i in range(len(spiketrain)):\n",
    "        if actual_pattern<len(pattern_times)-1:\n",
    "            if spiketrain[i]>pattern_times[actual_pattern+1]:\n",
    "                actual_pattern+=1\n",
    "        if spiketrain[i]>pattern_times[actual_pattern]+time_pattern:\n",
    "            new_spiketrain[actual_spike,0] = spiketrain[i]\n",
    "            new_spiketrain[actual_spike,1] = 0\n",
    "            actual_spike+=1\n",
    "\n",
    "    return actual_spike\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def pattern_placement(actual_spike,pattern_times,new_spiketrain,motifs_sizes,n,choices_patterns):\n",
    "    total_size = actual_spike\n",
    "    \n",
    "    for i in range(len(pattern_times)):\n",
    "        which_pattern_kind = choices_patterns[i]\n",
    "        which_pattern_pool = choices_pool[i]\n",
    "        motif = all_pattern_pools[n,which_pattern_kind,which_pattern_pool,:pattern_pools_sizes[n,which_pattern_kind,which_pattern_pool]]\n",
    "        new_spiketrain[total_size:total_size + len(motif),0] =motif+pattern_times[i]\n",
    "        new_spiketrain[total_size:total_size + len(motif),1] = np.ones(len(motif))\n",
    "        total_size += len(motif)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def pattern_placement_oscillation(actual_spike,pattern_times,new_spiketrain,motifs_sizes,n,choices_patterns):\n",
    "    total_size = actual_spike\n",
    "    \n",
    "    for i in range(len(pattern_times)):\n",
    "        which_pattern_kind = choices_patterns[i]\n",
    "        which_pattern_pool = choices_pool[i]\n",
    "        phase = (pattern_times[i]%times_phase[-1])\n",
    "        which_phase = np.abs(times_phase-phase).argmin()+1\n",
    "        motif = all_pattern_pools[n,which_pattern_kind,which_phase,which_pattern_pool,:pattern_pools_sizes[n,which_pattern_kind,which_phase,which_pattern_pool]]\n",
    "        new_spiketrain[total_size:total_size + len(motif),0] = motif+pattern_times[i]\n",
    "        new_spiketrain[total_size:total_size + len(motif),1] = np.ones(len(motif))\n",
    "        total_size += len(motif)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "# @numba.jit(nopython=True)\n",
    "# def copy_data(datas,fill_until,total_size,new_spiketrain,n):\n",
    "#         datas[fill_until:fill_until+total_size,0] = new_spiketrain[:total_size]\n",
    "#         datas[fill_until:fill_until+total_size,1] = np.full(total_size,n)\n",
    "#         return fill_until+total_size\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def copy_data(datas,fill_until,total_size,new_spiketrain,n):\n",
    "    datas[fill_until:fill_until+total_size,0] = new_spiketrain[:total_size,0]\n",
    "    datas[fill_until:fill_until+total_size,1] = np.full(total_size,n)\n",
    "    datas[fill_until:fill_until+total_size,2] =  new_spiketrain[:total_size,1]\n",
    "    return fill_until+total_size\n",
    "\n",
    "def pattern_pool_oscillation(n,index_pat_kind):\n",
    "    pattern_train = homogeneous_poisson_process((rate+var_rate)*pq.Hz,t_start=0*pq.s,t_stop=time_pattern*pq.s,as_array=True)\n",
    "    pattern_signal = np.zeros(int(time_pattern/delta_pat))\n",
    "    osc_pattern_trains = dict()\n",
    "    all_signals=dict()\n",
    "    #print(pattern_train)\n",
    "    for i in pattern_train:\n",
    "        pattern_signal[int(i/delta_pat)]=1/delta_pat\n",
    "    #print(np.sum(pattern_signal))\n",
    "    pattern_signal_convolveld = np.convolve(pattern_signal,kern)/np.sum(kern)\n",
    "    #print(np.sum(pattern_signal_convolveld))\n",
    "    for t in sin_signals_pattern:\n",
    "        osc = sin_signals_pattern[t]\n",
    "        osc_pattern_trains[t] = []\n",
    "        oscillation_pattern = osc[:-1]*pattern_signal_convolveld\n",
    "        #print(np.sum(oscillation_pattern))\n",
    "        all_signals[t] = TimeFunction((extanded_sample_pattern[:-1], oscillation_pattern), dt=delta_pat)\n",
    "\n",
    "    for j in range(len(times_phase)):\n",
    "        t = times_phase[j]\n",
    "        sim = SimuInhomogeneousPoisson([all_signals[t]], end_time=(time_pattern)*2, verbose=False)\n",
    "        for p in range(pool_size):\n",
    "            sim.simulate()\n",
    "            motif = sim.timestamps[0]\n",
    "            #print(all_pattern_pools[n,index_pat_kind,j,p,:len(motif)])\n",
    "            all_pattern_pools[n,index_pat_kind,j,p,:len(motif)] = motif\n",
    "            pattern_pools_sizes[n,index_pat_kind,j,p] = len(motif)\n",
    "            sim.reset()\n",
    "\n",
    "    return osc_pattern_trains\n",
    "\n",
    "def pattern_pool(n,index_pat_kind):\n",
    "    \n",
    "    pattern_train = homogeneous_poisson_process((rate)*pq.Hz,t_start=0*pq.s,t_stop=time_pattern*pq.s,as_array=True)\n",
    "    pattern_signal = np.zeros(int(time_pattern/delta_pat))\n",
    "    pattern_trains = []\n",
    "    #print(pattern_train)\n",
    "    for i in pattern_train:\n",
    "        pattern_signal[int(i/delta_pat)]=1/delta_pat\n",
    "    #print(np.sum(pattern_signal))\n",
    "    pattern_signal_convolveld = np.convolve(pattern_signal,kern)/np.sum(kern)\n",
    "    timefunction = TimeFunction((extanded_sample_pattern[:-1], pattern_signal_convolveld), dt=delta_pat)\n",
    "    #print(np.sum(pattern_signal_convolveld))\n",
    "\n",
    "    sim = SimuInhomogeneousPoisson([timefunction], end_time=(time_pattern)*2, verbose=False)\n",
    "    for p in range(pool_size):\n",
    "        sim.simulate()\n",
    "        motif = sim.timestamps[0]\n",
    "        all_pattern_pools[n,index_pat_kind,p,:len(motif)] = motif\n",
    "        pattern_pools_sizes[n,index_pat_kind,p] = len(motif)\n",
    "        sim.reset()\n",
    "\n",
    "    return pattern_trains \n",
    "\n",
    "\n",
    "def simulate_no_pattern_neuron(n):\n",
    "\n",
    "    if not oscillation:\n",
    "        spiketrain = homogeneous_poisson_process(rate*pq.Hz,t_start=start,t_stop=start+time_seg,as_array=True)\n",
    "    else:\n",
    "        sim = SimuInhomogeneousPoisson([sign], end_time=time_seg, verbose=False)\n",
    "        sim.simulate()\n",
    "        spiketrain = sim.timestamps[0]+start\n",
    "\n",
    "    return spiketrain,n,len(spiketrain)\n",
    "\n",
    "\n",
    "def simulate_pattern_neuron(n):\n",
    "   \n",
    "    if not oscillation:\n",
    "        spiketrain = homogeneous_poisson_process(rate*pq.Hz,t_start=start,t_stop=start+time_seg,as_array=True)\n",
    "    else:\n",
    "        sim = SimuInhomogeneousPoisson([sign], end_time=time_seg, verbose=False)\n",
    "        sim.simulate()\n",
    "        spiketrain = sim.timestamps[0]+start\n",
    "    #new_spiketrain = np.empty( int(((rate*time_sim)/nb_segment)*10) ,dtype=np.float32)\n",
    "\n",
    "    if len(spiketrain)>0:\n",
    "        if s == 0 :\n",
    "            for i in range(nb_pattern):\n",
    "                # make_motif\n",
    "                if not oscillation:\n",
    "                    pattern_pool(n,i)\n",
    "                    \n",
    "                else :\n",
    "                    pattern_pool_oscillation(n,i)\n",
    "\n",
    "\n",
    " \n",
    "        actual_spike = outside_pattern(spiketrain,new_spiketrain,pattern_times)\n",
    "        if not oscillation:\n",
    "            total_size = pattern_placement(actual_spike,pattern_times,new_spiketrain,motifs_sizes,n,choices_patterns)\n",
    "        else :\n",
    "            total_size = pattern_placement_oscillation(actual_spike,pattern_times,new_spiketrain,motifs_sizes,n,choices_patterns)\n",
    "\n",
    "\n",
    "        return new_spiketrain[:total_size],n,total_size\n",
    "    \n",
    "    return spiketrain,n,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "earlier-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 10\n",
    "var_rate = 10\n",
    "oscillation = False\n",
    "frequency = 36\n",
    "time_sim = 1000\n",
    "sampling_rate = 11\n",
    "nb_neurons = 10\n",
    "nb_segment = 1\n",
    "outdir = \".\"\n",
    "pattern = True\n",
    "\n",
    "if pattern :\n",
    "    time_pattern = 0.1\n",
    "    nb_pattern = 1\n",
    "    sparsity_pattern = 1\n",
    "    pattern_frequency = 3\n",
    "    ref_pattern = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hourly-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pattern:\n",
    "    Lin_func_kern =lambda x,sigma: np.exp(-np.square(x/sigma))\n",
    "    delta_pat = 0.002\n",
    "    pool_size = 1000\n",
    "    sample_kern = np.linspace(0,time_pattern,int(time_pattern/delta_pat))\n",
    "    membran_time = 0.01\n",
    "    kern = Lin_func_kern(sample_kern-time_pattern/2,membran_time)\n",
    "if oscillation:\n",
    "    samples = np.linspace(0,time_sim,time_sim*sampling_rate*frequency)\n",
    "    sin_signal = np.sin(samples*frequency*np.pi*2)\n",
    "    signal = rate +(var_rate*sin_signal)\n",
    "    sign = TimeFunction((samples, signal), dt=1/(sampling_rate*frequency))\n",
    "\n",
    "\n",
    "\n",
    "not_concerned_neurons = set(range(nb_neurons))\n",
    "concerned_neurons= set()\n",
    "\n",
    "if pattern:\n",
    "\n",
    "    sample_pattern = np.linspace(0,time_pattern,int(time_pattern/delta_pat))\n",
    "    extanded_sample_pattern = np.linspace(0,2*time_pattern,int((time_pattern*2)/delta_pat))\n",
    "    times_phase = np.array([t for t in np.linspace(0,np.pi*2,sampling_rate)])\n",
    "    raw_sin_signals_pattern= np.array([np.sin(extanded_sample_pattern*frequency*np.pi*2+t) for t in times_phase]) #replace per sampling rate\n",
    "    scaled_sin_signals_pattern = ((raw_sin_signals_pattern/2)*((var_rate)/rate))+(1-((var_rate)/rate)/2)\n",
    "    sin_signals_pattern = dict(zip(times_phase,scaled_sin_signals_pattern))\n",
    "\n",
    "    new_spiketrain = np.empty( (int(((rate*time_sim)/nb_segment)*10),2 ) ,dtype=np.float32) #change size for longer simulations\n",
    "    all_motifs = np.empty((nb_neurons,nb_pattern,int(((rate*time_pattern))*20)))\n",
    "    motifs_sizes = np.empty((nb_neurons,nb_pattern),dtype=int)\n",
    "    concerned_neurons = set( np.random.choice(range(nb_neurons),int(nb_neurons*sparsity_pattern), replace = False))\n",
    "    not_concerned_neurons = not_concerned_neurons.difference(concerned_neurons)\n",
    "    all_pattern_times = np.empty((int(time_sim*pattern_frequency*5),2))\n",
    "    actual_nb_pattern = 0\n",
    "\n",
    "    if oscillation:\n",
    "        all_pattern_pools = np.empty((nb_neurons,nb_pattern,len(times_phase),pool_size,int(((rate*time_pattern))*20)))\n",
    "        pattern_pools_sizes = np.empty((nb_neurons,nb_pattern,len(times_phase),pool_size),dtype=int)\n",
    "    else :\n",
    "        all_pattern_pools = np.empty((nb_neurons,nb_pattern,pool_size,int(((rate*time_pattern))*20)))\n",
    "        pattern_pools_sizes = np.empty((nb_neurons,nb_pattern,pool_size),dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "multiple-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "datas = np.empty((int(((rate*time_sim*nb_neurons)/nb_segment)*2),3),dtype=np.float32)\n",
    "time_seg =  (time_sim/nb_segment)*pq.s\n",
    "# %%\n",
    "for s in range(nb_segment):\n",
    "    start = time_seg*s\n",
    "    if pattern:\n",
    "        pattern_times = homogeneous_poisson_process(pattern_frequency*pq.Hz,t_start=start,t_stop =time_seg*(s+1),refractory_period = (time_pattern+ref_pattern)*pq.s, as_array=True )\n",
    "        choices_patterns = np.random.randint(0,nb_pattern,len(pattern_times))\n",
    "        choices_pool = np.random.randint(0,pool_size,len(pattern_times))\n",
    "\n",
    "        all_pattern_times[actual_nb_pattern:actual_nb_pattern+len(pattern_times),0]=pattern_times\n",
    "        all_pattern_times[actual_nb_pattern:actual_nb_pattern+len(pattern_times),1]=choices_patterns\n",
    "        \n",
    "        actual_nb_pattern+=len(pattern_times)\n",
    "\n",
    "    fill_until = 0\n",
    "\n",
    "\n",
    "    with Pool(processes=36) as pool:\n",
    "\n",
    "        multiple_thread = [pool.apply_async(simulate_no_pattern_neuron,(n,)) for n in not_concerned_neurons]\n",
    "        \n",
    "        for res in multiple_thread:\n",
    "            final_spike_train,n,total_size=res.get()\n",
    "            final_spike_train_color = np.array([final_spike_train,np.zeros(len(final_spike_train))]).T\n",
    "            print(n)\n",
    "            fill_until = copy_data(datas,fill_until,total_size,final_spike_train,n)\n",
    "    \n",
    "    if len(concerned_neurons)>0:\n",
    "\n",
    "        with Pool(processes=36) as pool:\n",
    "        \n",
    "            multiple_thread = [pool.apply_async(simulate_pattern_neuron,(n,)) for n in concerned_neurons]\n",
    "\n",
    "            for res in multiple_thread:\n",
    "                final_spike_train,n,total_size=res.get()\n",
    "                print(n)\n",
    "                fill_until = copy_data(datas,fill_until,total_size,final_spike_train,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minute-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7b457f5fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter([1,2,3],[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
